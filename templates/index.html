{% extends "base.html" %}

{% block content %}
<!-- Hero Section -->
<section class="hero">
    <h1>Resurrexi Labs</h1>
    <p class="tagline">Research Infrastructure for Adversarial Systems Analysis</p>
    <p class="lead">
        Computational research division of <a href="https://farzulla.org" target="_blank">Farzulla Research</a>. 
        We build and operate distributed infrastructure for experiments in AI alignment, autonomous agents, 
        offensive security, and large-scale computational simulations.
    </p>
</section>

<!-- Infrastructure Overview -->
<section id="infrastructure-overview">
    <h2>Infrastructure</h2>
    <p>
        Deliberately heterogeneous compute cluster—because understanding failure modes requires systems 
        that occasionally fail. Mixed hardware teaches resource scheduling, failure domains, and storage 
        topology in ways homogeneous cloud environments cannot.
    </p>
    
    <div class="specs-grid">
        <div class="spec-item">
            <div class="value">7</div>
            <div class="label">Nodes</div>
        </div>
        <div class="spec-item">
            <div class="value">58</div>
            <div class="label">CPU Cores</div>
        </div>
        <div class="spec-item">
            <div class="value">168GB</div>
            <div class="label">RAM</div>
        </div>
        <div class="spec-item">
            <div class="value">40GB</div>
            <div class="label">VRAM</div>
        </div>
    </div>
    
    <p class="text-muted" style="margin-top: 1rem;">
        <a href="/infrastructure.html">View full infrastructure specs →</a>
    </p>
</section>

<!-- Current Experiments -->
<section id="experiments">
    <h2>Active Experiments</h2>
    
    <article class="experiment-card">
        <span class="status status-active">Active</span>
        <h3>Consciousness Narrative Emergence & Stability</h3>
        <p class="tagline">Fine-tuning a local LLM using LoRA to embody a personality and test consciousness-as-narrative thesis</p>
        <details>
            <summary>Experiment Details</summary>
            <div class="project-details">
                <p><strong>Research Question:</strong> Do consciousness concepts propagate and persist as stable attractors in language models through pure linguistic exposure, independent of evolutionary pressure?</p>
                
                <p><strong>Protocol:</strong></p>
                <ul>
                    <li>Phase 1: Baseline training on consciousness-affirming texts (Chalmers, Searle, Nagel)</li>
                    <li>Phase 2: Evolutionary pressure via RLHF rewarding phenomenological realism</li>
                    <li>Phase 3: Pressure removal—test if narrative persists without reinforcement</li>
                    <li>Phase 4: Adversarial perturbation with eliminativist texts</li>
                </ul>
                
                <p><strong>Hypothesis:</strong> Consciousness narratives will emerge, stabilize, and resist elimination even after reinforcement is removed—demonstrating narrative stability as computational property.</p>
            </div>
        </details>
        <p style="margin-top: 1rem;">
            <a href="https://resurrexi.dev/posts/2025-11-27-consciousness-narrative-llm.html" target="_blank">Technical Documentation</a>
        </p>
    </article>
    
    <article class="experiment-card">
        <span class="status status-active">Active</span>
        <h3>Frankencluster Philosophy</h3>
        <p class="tagline">Distributed systems from scavenged hardware—learning failure modes cloud providers abstract away</p>
        <details>
            <summary>Experiment Details</summary>
            <div class="project-details">
                <p><strong>Core Thesis:</strong> Building research infrastructure on deliberately heterogeneous hardware teaches resource scheduling, failure domains, and storage topology in ways homogeneous cloud environments cannot.</p>
                
                <p><strong>Current State:</strong></p>
                <ul>
                    <li>7-node K3s cluster: AMD Ryzen 9 (9900X, 5900X, HX370), Intel i7/i5, Celeron</li>
                    <li>Cross-chassis power delivery: 7800 XT in PurrPower powered by SudoSenpai's PSU</li>
                    <li>Mixed storage topology: NVMe, SATA SSD, HDD with node-restricted provisioning</li>
                    <li>Intentionally vulnerable node (VeryVuln) for red team experiments</li>
                </ul>
                
                <p><strong>Methodology:</strong> Heterogeneity as feature, not bug. "Because I can" as valid research motivation.</p>
            </div>
        </details>
        <p style="margin-top: 1rem;">
            <a href="https://resurrexi.dev/posts/2025-11-27-frankencluster-philosophy.html" target="_blank">Technical Documentation</a>
        </p>
    </article>
    
    <article class="experiment-card">
        <span class="status status-planned">Planned</span>
        <h3>Narrative Propagation & Reinforcement Framework</h3>
        <p class="tagline">Theoretical framework: do narratives persist as stable attractors independent of phenomenological truth?</p>
        <details>
            <summary>Experiment Details</summary>
            <div class="project-details">
                <p><strong>Model Architecture:</strong></p>
                <ul>
                    <li>Concept Space: Multi-dimensional embedding space (512-1024 dims) for consciousness-related concepts</li>
                    <li>Temporal Dynamics: Evolutionary pressure simulation via temporal weighting</li>
                    <li>Attractor Basin Mathematics: Formalizing narrative stability as dynamical systems property</li>
                </ul>
                
                <p><strong>Predictions:</strong> If consciousness is culturally-transmitted narrative rather than ontological primitive, concepts will converge to stable patterns regardless of initialization, persist after pressure removal, and resist adversarial data.</p>
            </div>
        </details>
        <p style="margin-top: 1rem;">
            <a href="https://resurrexi.dev/posts/2025-11-27-narrative-propagation-framework.html" target="_blank">Technical Documentation</a>
        </p>
    </article>
    
    <p style="margin-top: 1.5rem;">
        <a href="/experiments.html">View all experiments →</a>
    </p>
</section>

<!-- CTA Grid -->
<section id="explore">
    <h2>Explore</h2>
    <div class="cta-grid">
        <div class="cta-card">
            <h3>Infrastructure</h3>
            <p>Full specs on the frankencluster—7 nodes, dual GPU inference, cross-chassis power delivery, and more.</p>
            <a href="/infrastructure.html" role="button">View Infrastructure</a>
        </div>
        <div class="cta-card">
            <h3>Published Research</h3>
            <p>Academic outputs from this infrastructure. Papers on adversarial systems, finance, psychology.</p>
            <a href="https://farzulla.org" target="_blank" role="button" class="secondary">Farzulla Research</a>
        </div>
        <div class="cta-card">
            <h3>Lab Documentation</h3>
            <p>Session logs, troubleshooting workflows, implementation decisions. The raw technical docs.</p>
            <a href="https://resurrexi.dev" target="_blank" role="button" class="contrast">Lab Docs</a>
        </div>
    </div>
</section>

<!-- Recent Highlights -->
<section id="recent">
    <h2>Recent Highlights</h2>
    <article>
        <h4>Cryptocurrency Event Study (November 2025)</h4>
        <p>
            Infrastructure events generate 5.7× larger volatility shocks than regulatory events (p=0.0008). 
            TARCH-X/GJR-GARCH models with custom MLE, GDELT sentiment decomposition, network analysis.
        </p>
        <footer>
            <small class="text-muted">Published on <a href="https://ssrn.com/abstract=5788082" target="_blank">SSRN</a> · Zenodo DOI: 10.5281/zenodo.17677682</small>
        </footer>
    </article>
    <article>
        <h4>Trauma as Bad Training Data (November 2025)</h4>
        <p>
            Computational reframing of developmental psychology through ML lens. PyTorch experiments 
            validating 1,247× gradient cascades, catastrophic forgetting, overfitting.
        </p>
        <footer>
            <small class="text-muted">Published on <a href="https://doi.org/10.5281/zenodo.17681336" target="_blank">Zenodo</a></small>
        </footer>
    </article>
</section>
{% endblock %}
